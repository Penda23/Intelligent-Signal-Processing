{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda205f3",
   "metadata": {},
   "source": [
    "# Installing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73df664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /Users/Penda/anaconda3/lib/python3.11/site-packages (4.11.0.86)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/Penda/anaconda3/lib/python3.11/site-packages (from opencv-contrib-python) (1.24.3)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3828ba",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de1ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e662fa",
   "metadata": {},
   "source": [
    "# Loading and Processing Video Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1338e0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video Properties for Traffic_Laramie_1.mp4:\n",
      "  - Frame Width: 1040 pixels\n",
      "  - Frame Height: 600 pixels\n",
      "  - Frame Rate: 25.00 FPS\n",
      "  - Total Frames: 4448\n",
      "  - Duration: 177.92 seconds\n",
      "\n",
      "Video Properties for Traffic_Laramie_2.mp4:\n",
      "  - Frame Width: 1040 pixels\n",
      "  - Frame Height: 600 pixels\n",
      "  - Frame Rate: 25.00 FPS\n",
      "  - Total Frames: 2642\n",
      "  - Duration: 105.68 seconds\n"
     ]
    }
   ],
   "source": [
    "# List of video files\n",
    "video_paths = [\"Traffic_Laramie_1.mp4\", \"Traffic_Laramie_2.mp4\"]\n",
    "\n",
    "# Loop through each video and display properties\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        continue  # Skip to the next video if it can't be opened\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # Width of the frames\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Height of the frames\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)                 # Frames per second\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "    duration = total_frames / frame_rate if frame_rate > 0 else 0  # Duration in seconds\n",
    "\n",
    "    # Print video properties\n",
    "    print(f\"\\nVideo Properties for {video_path}:\")\n",
    "    print(f\"  - Frame Width: {frame_width} pixels\")\n",
    "    print(f\"  - Frame Height: {frame_height} pixels\")\n",
    "    print(f\"  - Frame Rate: {frame_rate:.2f} FPS\")\n",
    "    print(f\"  - Total Frames: {total_frames}\")\n",
    "    print(f\"  - Duration: {duration:.2f} seconds\")\n",
    "\n",
    "    cap.release()  # Release video capture before moving to the next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9406937",
   "metadata": {},
   "source": [
    "# Function to identify car and background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f370a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_counter(video_cap, bg_sub):\n",
    "    '''\n",
    "    This function tracks and counts moving cars in a specified area using background subtraction.\n",
    "    '''\n",
    "\n",
    "    # Check if the video file was successfully opened\n",
    "    if not video_cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    amount_of_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "    video_fps = video_cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "    video_duration = amount_of_frames / video_fps if video_fps > 0 else 1  # Avoid division by zero\n",
    "\n",
    "    # Initialize variables for tracking\n",
    "    previous_frame_centroids = []  # Stores centroids from previous frame\n",
    "    tracked_objects = {}  # Dictionary to track objects\n",
    "    tracking_id = 0  # Unique ID for each tracked object\n",
    "    car_counter = 0  # Counter for detected cars\n",
    "\n",
    "    # Process each frame in the video\n",
    "    for _ in range(amount_of_frames):\n",
    "        current_frame_centroids = []  # Stores centroids in the current frame\n",
    "\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"End of video or error reading frame.\")\n",
    "            break\n",
    "\n",
    "        # Define Region of Interest (ROI) to limit detection area\n",
    "        detection_area = frame[260:600, 0:1040]  \n",
    "\n",
    "        # Apply background subtraction to detect moving objects\n",
    "        fgmask = bg_sub.apply(detection_area)\n",
    "        _, fgmask = cv2.threshold(fgmask, 254, 255, cv2.THRESH_BINARY)  # Binarize the mask\n",
    "        contours, _ = cv2.findContours(fgmask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # Find object contours\n",
    "\n",
    "        # Loop through detected contours\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)  # Get contour area\n",
    "            x, y, w, h = cv2.boundingRect(cnt)  # Get bounding box for detected object\n",
    "\n",
    "            # Large objects, likely cars, split into two parts for better tracking\n",
    "            if x < 520 and area > 13500 and h > 130:\n",
    "                cx1, cy1 = int(x + (x + w) / 2), int(y + (y + h/2) / 2)\n",
    "                cx2, cy2 = int(x + (x + w) / 2), int(y + h/2 + (y + h/2) / 2)\n",
    "                current_frame_centroids.extend([(cx1, cy1), (cx2, cy2)])\n",
    "\n",
    "                # Draw bounding boxes around detected cars\n",
    "                cv2.rectangle(detection_area, (x, y), (x + w, y + int(h/2)), (0, 255, 0), 1)\n",
    "                cv2.rectangle(detection_area, (x, y + int(h/2)), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "            # Smaller objects, also likely vehicles\n",
    "            elif area > 4700:\n",
    "                cx, cy = int(x + (x + w) / 2), int(y + (y + h) / 2)\n",
    "                current_frame_centroids.append((cx, cy))\n",
    "                \n",
    "                # Draw a bounding box around detected objects\n",
    "                cv2.rectangle(detection_area, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "        # Track detected objects using centroids\n",
    "        for ccentroid in current_frame_centroids:\n",
    "            nearest_track_obj = []  # Store the closest tracked object\n",
    "\n",
    "            for object_key in tracked_objects:\n",
    "                tracked_obj = tracked_objects[object_key]\n",
    "                # Calculate Euclidean distance between tracked and current centroid\n",
    "                distance = math.sqrt((tracked_obj[0] - ccentroid[0])**2 + (tracked_obj[1] - ccentroid[1])**2)\n",
    "\n",
    "                # If the object is within a reasonable distance, track it\n",
    "                if distance < 100:\n",
    "                    if nearest_track_obj and nearest_track_obj[2] > distance:\n",
    "                        nearest_track_obj = [ccentroid[0], ccentroid[1], distance, tracked_obj[2]]\n",
    "                    elif not nearest_track_obj:\n",
    "                        nearest_track_obj = [ccentroid[0], ccentroid[1], distance, tracked_obj[2]]\n",
    "\n",
    "            # If no nearby tracked object is found, assign a new tracking ID\n",
    "            if not nearest_track_obj:\n",
    "                tracked_objects[tracking_id] = [ccentroid[0], ccentroid[1], tracking_id, True]\n",
    "                tracking_id += 1\n",
    "            else:\n",
    "                update_track_id = nearest_track_obj[3]\n",
    "                tracked_objects[update_track_id] = [ccentroid[0], ccentroid[1], update_track_id, True]\n",
    "\n",
    "            # Clear temporary tracking object\n",
    "            nearest_track_obj.clear()\n",
    "\n",
    "        # Remove old tracked objects and count cars if they exit the frame\n",
    "        for object_key in list(tracked_objects.keys()):\n",
    "            centroid = tracked_objects[object_key]\n",
    "            if centroid[3]:\n",
    "                tracked_objects[centroid[2]][3] = False\n",
    "            else:\n",
    "                if centroid[0] < 215:  # If the object moves past a certain point\n",
    "                    car_counter += 1  # Increase car count\n",
    "                del tracked_objects[centroid[2]]  # Remove old tracked objects\n",
    "\n",
    "        # Display the car count on the video frame\n",
    "        cv2.putText(frame, 'Cars Going to City Center: ', (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(car_counter), (500, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the processed video frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Press 'q' to stop the video early\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Print final car count and statistics\n",
    "    print(f\"Total cars going to city center: {car_counter}\")\n",
    "    print(f\"Cars per minute: {round(car_counter / (video_duration / 60), 2)}\")\n",
    "\n",
    "    # Release video capture and close all OpenCV windows\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682f9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: Traffic_Laramie_1.mp4\n",
      "Total cars going to city center: 6\n",
      "Cars per minute: 2.02\n",
      "Processing video: Traffic_Laramie_2.mp4\n",
      "Total cars going to city center: 6\n",
      "Cars per minute: 3.41\n"
     ]
    }
   ],
   "source": [
    "# List of video files\n",
    "video_files = ['Traffic_Laramie_1.mp4', 'Traffic_Laramie_2.mp4']\n",
    "\n",
    "# Loop through both videos without modifying the main processing code\n",
    "for video_path in video_files:\n",
    "    video_cap = cv2.VideoCapture(video_path)  # Open the video\n",
    "\n",
    "    # Initialize background subtractor (you can reuse it)\n",
    "    bg_sub = cv2.createBackgroundSubtractorMOG2(history=15000, varThreshold=20, detectShadows=False)\n",
    "\n",
    "    if not video_cap.isOpened():\n",
    "        print(f\"Failed to open {video_path}\")\n",
    "        continue  # Skip to the next video\n",
    "\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "\n",
    "    # Run your existing car counting code here, unchanged\n",
    "    # (Make sure your car_counter function is defined and used here)\n",
    "    car_counter(video_cap, bg_sub)\n",
    "\n",
    "    # Release video capture after processing\n",
    "    video_cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows after processing both videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9c48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
